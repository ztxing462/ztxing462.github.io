```python
#导入库并产生数据
import math
import numpy as np
import torch
from torch.utils import data
import random

#定义正态分布
def normal(x,mu,sigma):
    p=1/math.sqrt(2*math.pi*sigma*sigma)
    return p*np.exp(-0.5/sigma**2 *(x-mu)**2)

#制造数据集 y=Xw+b+噪声
def synthetic_data(w, b, num_examples): 
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 100)
```


```python
#"""构造⼀个PyTorch数据迭代器"""
def load_array(data_arrays, batch_size, is_train=True): 
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)
batch_size = 10
data_iter = load_array((features, labels), batch_size)
print(next(iter(data_iter)))
```

    [tensor([[-0.3579,  1.4741],
            [ 0.0645,  0.1303],
            [-0.6813,  0.3311],
            [-1.1359, -0.5278],
            [ 1.1961, -1.6108],
            [-1.1505, -1.2158],
            [-0.0079,  0.4013],
            [-2.2382,  0.6464],
            [ 0.4329, -0.5733],
            [-2.0820,  0.2611]]), tensor([[-1.5409],
            [ 3.8748],
            [ 1.7072],
            [ 3.7083],
            [12.0702],
            [ 6.0219],
            [ 2.8221],
            [-2.4616],
            [ 7.0099],
            [-0.8344]])]
    


```python
#建立模型
from torch import nn
#nn.linear第一个参数为输入的特征，第二个为输出量
net=nn.Sequential(nn.Linear(2,1))
#初始化模型参数
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
#定义损失函数
loss = nn.MSELoss()
#定义优化器
sgd=torch.optim.SGD([{"params":net[0].weight,'weight_decay': 0.03},
{"params":net[0].bias}], lr=0.1)

```


```python
num_epochs = 10
for epoch in range(num_epochs):
    for X,y in data_iter:
        l=loss(net(X),y)
        sgd.zero_grad()
        l.backward()
        sgd.step()
    l=loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {float(l):f}')

print([true_w,true_b])
print([net[0].weight.data,net[0].bias.data])
```

    epoch 1, loss 0.327184
    epoch 2, loss 0.007667
    epoch 3, loss 0.003351
    epoch 4, loss 0.003138
    epoch 5, loss 0.003384
    epoch 6, loss 0.002787
    epoch 7, loss 0.003684
    epoch 8, loss 0.002339
    epoch 9, loss 0.002739
    epoch 10, loss 0.003299
    [tensor([ 2.0000, -3.4000]), 4.2]
    [tensor([[ 1.9746, -3.3536]]), tensor([4.1969])]
    

    C:\Users\11215\anaconda3\lib\site-packages\torch\autograd\__init__.py:173: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  C:\cb\pytorch_1000000000000\work\c10\cuda\CUDAFunctions.cpp:112.)
      Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
    


```python
#建立模型
from torch import nn
#nn.linear第一个参数为输入的特征，第二个为输出量
net=nn.Sequential(nn.Linear(2,1))
#初始化模型参数
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
#定义损失函数
loss = nn.SmoothL1Loss()
#定义优化器
sgd=torch.optim.SGD(net.parameters(), lr=0.03)

```


```python
num_epochs = 10
for epoch in range(num_epochs):
    for X,y in data_iter:
        l=loss(net(X),y)
        sgd.zero_grad()
        l.backward()
        sgd.step()
    l=loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {float(l):f}')

print([true_w,true_b])
print([net[0].weight.data,net[0].bias.data])
```

    epoch 1, loss 4.162839
    epoch 2, loss 3.949262
    epoch 3, loss 3.736193
    epoch 4, loss 3.523710
    epoch 5, loss 3.311804
    epoch 6, loss 3.100526
    epoch 7, loss 2.889958
    epoch 8, loss 2.680083
    epoch 9, loss 2.470948
    epoch 10, loss 2.262843
    [tensor([ 2.0000, -3.4000]), 4.2]
    [tensor([[ 0.9426, -1.5283]]), tensor([1.7682])]
    
